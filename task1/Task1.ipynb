{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7927fedb",
   "metadata": {
    "cell_id": "95674e6b-b484-4d5b-ad41-9966ec29eb98",
    "deepnote_cell_height": 606,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Introduction\n",
    "Semantic textual similarity deals with determining how similar a pair of text documents are. The goal of the first task is to implement a new architecture by combining the ideas from papers\n",
    "- Siamese Recurrent Architectures for Learning Sentence Similarity, Jonas Mueller et. al (will be referred as the AAAI paper)\n",
    "- A Structured Self-Attentive Sentence Embedding, Zhouhan Lin et. al (will be referred as the ICLR paper) <br/><br/>\n",
    "Furthermore, you'd be evaluating whether the new architecture improves the results of **Siamese Recurrent Architectures for Learning Sentence Similarity, Jonas Mueller et. al**. Your overall network architecture should look similar to the following figure. \n",
    "![Untitled%20Diagram.drawio%20%281%29.png](https://raw.githubusercontent.com/shahrukhx01/ocr-test/main/download.png)\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "Moreover, you'd be required to implement further helper functions that these papers propose i.e., attention penalty term for loss, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c6a01c",
   "metadata": {
    "cell_id": "00001-e56fd0e5-f60f-48d7-8308-54a79498a817",
    "deepnote_cell_height": 288.1875,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### SICK dataset\n",
    "We will use SICK dataset throughout the project (at least in the first two tasks). To get more information about the dataset you can refer to the original [paper](http://www.lrec-conf.org/proceedings/lrec2014/pdf/363_Paper.pdf) on the dataset. You can download the dataset using one of the following links:\n",
    "- [dataset page 1](https://marcobaroni.org/composes/sick.html)\n",
    "- [dataset page 2](https://huggingface.co/datasets/sick)    \n",
    "\n",
    "The relevant columns for the project are `sentence_A`, `sentence_B`, `relatedness_score`, where `relatedness_score` is the label. <br><br>\n",
    "**Hint: For each task make sure to decide whether the label should be normalized or not.**<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f91ffcc",
   "metadata": {
    "cell_id": "00003-855bba9a-be44-4898-b0e7-68cfa649cc58",
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 71,
    "execution_start": 1647000867386,
    "source_hash": "2f19d1f9"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a173aca",
   "metadata": {
    "cell_id": "00004-983e8828-2d66-45ad-afd3-1cca25b2b0e0",
    "deepnote_cell_height": 135,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 7189,
    "execution_start": 1647000973909,
    "source_hash": "465fb797"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import test\n",
    "import sts_data\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "678beaa2",
   "metadata": {
    "cell_id": "00005-05bf0a23-9310-4a89-94ee-e97692538515",
    "deepnote_cell_height": 131,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 1. Data pipeline (3 points)\n",
    "Before starting working on the model, we must configure the data pipeline to load the data in the correct format. Please, implement the functions for processing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9eb56",
   "metadata": {
    "cell_id": "00006-ebe96542-df37-406a-afa2-32a755daca8b",
    "deepnote_cell_height": 330.59375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Part 1.1 Loading and preprocessing the data (1 point)\n",
    "Download the SICK dataset and store it in [pandas](https://pandas.pydata.org/docs/index.html) `Dataframe`'s. You should use the official data split.  \n",
    "\n",
    "Implement `load_data` method of `STSData` class in `sts_data.py`. The method must download the dataset and perform basic preprocessing. Minimal preprocessing required:  \n",
    "1. normalize text to lower case\n",
    "2. remove punctuations  \n",
    "3. remove [stopwords](https://en.wikipedia.org/wiki/Stop_word) - we provided you with the list of English stopwords.\n",
    "4. Optionally, any other preprocessing that you deem necessary.\n",
    "\n",
    "All the preprocessing code must be contained in the `preprocessing.py` file.  \n",
    "You can use Hugginface's [datasets library](https://huggingface.co/docs/datasets/) for easy dataset download."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ddab28",
   "metadata": {
    "cell_id": "00007-f82b92b8-42b7-40a0-9bf9-da348c6fca21",
    "deepnote_cell_height": 280,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Part 1.2 Building vocabulary (1 point)\n",
    "Before we can feed our text to the model it must be vectorized. We use 300 dimensional pretrained [FastText embeddings](https://fasttext.cc/docs/en/english-vectors.html) for mapping words to vectors. To know more general information about embeddings you can refer to [this video](https://www.youtube.com/watch?v=ERibwqs9p38) (even though, we use different types of embeddings - FastText vs Word2Vec described in the video - the general purpose of them is the same).  \n",
    "In order to apply the embedding, we must first construct the vocabulary for data. Complete the `create_vocab` method of `STSData` class in `sts_data.py` where you concatenate each sentence pair, tokenize it and construct the vocabulary for the whole training data. You should use [torchtext](https://torchtext.readthedocs.io/en/latest/data.html\n",
    ") for processing the data. For tokenization, you can use any library (or write your own tokenizer), but we recommend you to use tokenizer by [spacy](https://spacy.io/). Use the `fasttext.simple.300d` as pretrained vectors.  \n",
    "In the end, you must have a vocabulary object capable of mapping your input to corresponding vectors. Remember that the vocabulary is created using only training data (not touching validation or test data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2b8c00",
   "metadata": {
    "cell_id": "00008-d0424254-bb21-4b97-85c9-fde816548980",
    "deepnote_cell_height": 345,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "### Part 1.3 Creating DataLoader (1 point)\n",
    "Implement `get_data_loader` method of `STSData` class in `sts_data.py`. It must perform the following operations on each of the data splits:\n",
    "1. vectorize each pair of the sentences by replacing all tokens with their index in vocabulary\n",
    "2. normalize labels\n",
    "3. convert everything to PyTorch tensors\n",
    "4. pad every sentence so that all of them have the same length\n",
    "5. create `STSDataset` from `dataset.py`\n",
    "6. create PyTorch DataLoader out of the created dataset. \n",
    "\n",
    "\n",
    "We have provided you with the interfaces of possible helper functions, but you can change them as you need.   \n",
    "In the end, you must have 3 data loaders for each of the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22266240",
   "metadata": {
    "cell_id": "00009-c4a95128-2ed7-40d9-80c9-d43b74a76942",
    "deepnote_cell_height": 520,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 5127,
    "execution_start": 1647000984730,
    "scrolled": true,
    "source_hash": "4cf21dba"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:loading and preprocessing data...\n",
      "INFO:root:reading and preprocessing data completed...\n",
      "INFO:root:creating vocabulary...\n",
      "INFO:torchtext.vocab:Loading vectors from .vector_cache/wiki.simple.vec.pt\n",
      "INFO:root:creating vocabulary completed...\n",
      "INFO:root:creating STSDataset completed...\n",
      "INFO:root:creating dataloaders completed...\n"
     ]
    }
   ],
   "source": [
    "reload(sts_data)\n",
    "from sts_data import STSData\n",
    "\n",
    "columns_mapping = {\n",
    "        \"sent1\": \"sentence_A\",\n",
    "        \"sent2\": \"sentence_B\",\n",
    "        \"label\": \"relatedness_score\",\n",
    "    }\n",
    "dataset_name = \"sick\"\n",
    "sick_data = STSData(\n",
    "    dataset_name=dataset_name,\n",
    "    columns_mapping=columns_mapping,\n",
    "    normalize_labels=True,\n",
    "    normalization_const=5.0,\n",
    ")\n",
    "batch_size = 64\n",
    "sick_dataloaders = sick_data.get_data_loader(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20543ad",
   "metadata": {
    "cell_id": "00011-26432306-083c-4b2a-93ae-848911c93855",
    "deepnote_cell_height": 423,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 2. Model Configuration & Hyperparameter Tuning (3 points)\n",
    "In this part, you are required to define a model capable of learning self-attentive sentence embeddings described in [this ICLR paper](https://arxiv.org/pdf/1703.03130.pdf). The sentence embedding learned by this model will be used for computing the similarity score instead of the simpler embeddings described in the original AAAI paper.  \n",
    "Please familiarize yourself with the model described in the ICLR paper and implement `SiameseBiLSTMAttention` and `SelfAttention` classes in `siamese_lstm_attention.py`. Remember that you must run the model on each sentence in the sentence pair to calculate the similarity between them. You can use `similarity_score` from `utils.py` to compute the similarity score between two sentences. \n",
    "  \n",
    "To get more theoretical information about attention mechanisms you can refer to [this chapter](https://web.stanford.edu/~jurafsky/slp3/10.pdf) of [\"Speech and Language Processing\" book](https://web.stanford.edu/~jurafsky/slp3/) by Dan Jurafsky and James H. Martin, where the attention mechanism is described in the context of the machine translation task. \n",
    "\n",
    "Finally, once your implementation works on the default parameters stated below, make sure to perform **hyperparameter tuning** to find the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71d277",
   "metadata": {
    "cell_id": "00012-b2501108-c4ac-47f5-bbbf-2953f4589719",
    "deepnote_cell_height": 369,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 53,
    "execution_start": 1647003005769,
    "source_hash": "cea6c3a3"
   },
   "outputs": [],
   "source": [
    "output_size = 1\n",
    "hidden_size = 128\n",
    "vocab_size = len(sick_data.vocab)\n",
    "embedding_size = 300\n",
    "embedding_weights = sick_data.vocab.vectors\n",
    "lstm_layers = 4\n",
    "learning_rate = 1e-1\n",
    "fc_hidden_size = 64\n",
    "max_epochs = 20\n",
    "bidirectional = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## self attention config\n",
    "self_attention_config = {\n",
    "    \"hidden_size\": 150,  ## refers to variable 'da' in the ICLR paper\n",
    "    \"output_size\": 20,  ## refers to variable 'r' in the ICLR paper\n",
    "    \"penalty\": 0.0,  ## refers to penalty coefficient term in the ICLR paper\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d05ec5",
   "metadata": {
    "cell_id": "8f780c6d-6dd8-4950-89de-fec81cb31a75",
    "deepnote_cell_height": 153,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 55,
    "execution_start": 1647003008060,
    "source_hash": "e53edc1f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from siamese_lstm_attention import SiameseBiLSTMAttention\n",
    "from train import train_model\n",
    "from test import evaluate_test_set\n",
    "from tuning import tune_model\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b350ab8",
   "metadata": {
    "cell_id": "29e42d9c-347e-4402-96d1-07fd0e175484",
    "deepnote_cell_height": 550.796875,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1832882,
    "execution_start": 1647003426389,
    "output_cleared": false,
    "source_hash": "f4f6e778",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-03-11 12:57:07,507]\u001b[0m A new study created in memory with name: no-name-89857217-9050-4cc6-a9a3-3db05824ecf3\u001b[0m\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]/opt/conda/lib/python3.8/site-packages/scipy/stats/_stats_py.py:4068: PearsonRConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n",
      "100%|██████████| 20/20 [11:44<00:00, 35.24s/it]\n",
      "\u001b[32m[I 2022-03-11 13:08:52,318]\u001b[0m Trial 0 finished with value: 0.001 and parameters: {'hidden_size': 128, 'lstm_layers': 12, 'learning_rate': 1.0, 'fc_hidden_size': 112, 'da': 50, 'r': 20, 'penalty': 0.4}. Best is trial 0 with value: 0.001.\u001b[0m\n",
      "100%|██████████| 20/20 [02:48<00:00,  8.41s/it]\n",
      "\u001b[32m[I 2022-03-11 13:11:40,448]\u001b[0m Trial 1 finished with value: 0.45686687703647466 and parameters: {'hidden_size': 64, 'lstm_layers': 4, 'learning_rate': 1e-05, 'fc_hidden_size': 64, 'da': 250, 'r': 10, 'penalty': 0.4}. Best is trial 1 with value: 0.45686687703647466.\u001b[0m\n",
      "100%|██████████| 20/20 [07:38<00:00, 22.92s/it]\n",
      "\u001b[32m[I 2022-03-11 13:19:18,902]\u001b[0m Trial 2 finished with value: 0.40026872829181787 and parameters: {'hidden_size': 128, 'lstm_layers': 8, 'learning_rate': 0.001, 'fc_hidden_size': 96, 'da': 300, 'r': 10, 'penalty': 0.4}. Best is trial 1 with value: 0.45686687703647466.\u001b[0m\n",
      "100%|██████████| 20/20 [06:10<00:00, 18.54s/it]\n",
      "\u001b[32m[I 2022-03-11 13:25:29,663]\u001b[0m Trial 3 finished with value: 0.08451711562953988 and parameters: {'hidden_size': 48, 'lstm_layers': 12, 'learning_rate': 1e-05, 'fc_hidden_size': 96, 'da': 200, 'r': 5, 'penalty': 1.0}. Best is trial 1 with value: 0.45686687703647466.\u001b[0m\n",
      "100%|██████████| 20/20 [02:09<00:00,  6.48s/it]\n",
      "\u001b[32m[I 2022-03-11 13:27:39,262]\u001b[0m Trial 4 finished with value: 0.6181212464262876 and parameters: {'hidden_size': 32, 'lstm_layers': 4, 'learning_rate': 1.0, 'fc_hidden_size': 128, 'da': 100, 'r': 10, 'penalty': 0.4}. Best is trial 4 with value: 0.6181212464262876.\u001b[0m\n",
      "hidden_size: 32\n",
      "lstm_layers: 4\n",
      "learning_rate: 1.0\n",
      "fc_hidden_size: 128\n",
      "da: 100\n",
      "r: 10\n",
      "penalty: 0.4\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameter Tuning\n",
    "\n",
    "# We use the Optuna framework here (reference below). It is a comprehensive platform-independent framework\n",
    "# with inbuilt sampling and pruning mechanisms. We found it helpful to use Optuna along with PyTorch.\n",
    "\n",
    "results = tune_model(sick_data, sick_dataloaders)\n",
    "for key, value in results.best_params.items():\n",
    "        print(\"{}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd5015",
   "metadata": {
    "cell_id": "69998472-e90b-4937-830e-4ae13c33f3f1",
    "deepnote_cell_height": 642,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     527
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 715,
    "execution_start": 1647005392852,
    "source_hash": "ca23862f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"e78335ae-4898-462b-a27e-dd42a22301cb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e78335ae-4898-462b-a27e-dd42a22301cb\")) {                    Plotly.newPlot(                        \"e78335ae-4898-462b-a27e-dd42a22301cb\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"hidden_size (IntUniformDistribution): 0.05265865459760126<extra></extra>\",\"fc_hidden_size (IntUniformDistribution): 0.0705979971605837<extra></extra>\",\"penalty (DiscreteUniformDistribution): 0.0749055976421243<extra></extra>\",\"learning_rate (CategoricalDistribution): 0.07779136879111538<extra></extra>\",\"r (IntUniformDistribution): 0.11193881079323972<extra></extra>\",\"da (IntUniformDistribution): 0.20136401993304076<extra></extra>\",\"lstm_layers (IntUniformDistribution): 0.4107435510822949<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.05265865459760126\",\"0.0705979971605837\",\"0.0749055976421243\",\"0.07779136879111538\",\"0.11193881079323972\",\"0.20136401993304076\",\"0.4107435510822949\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.05265865459760126,0.0705979971605837,0.0749055976421243,0.07779136879111538,0.11193881079323972,0.20136401993304076,0.4107435510822949],\"y\":[\"hidden_size\",\"fc_hidden_size\",\"penalty\",\"learning_rate\",\"r\",\"da\",\"lstm_layers\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e78335ae-4898-462b-a27e-dd42a22301cb');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting hyperparameter importances\n",
    "optuna.visualization.plot_param_importances(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4820d3",
   "metadata": {
    "cell_id": "a55c19d1-9c9f-4af1-ac6a-47fa7cce900f",
    "deepnote_cell_height": 642,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     527
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1255,
    "execution_start": 1647005428731,
    "source_hash": "cfdd6933",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-2.9.0.min.js\"></script>                <div id=\"f645bc77-8532-4793-9547-99c67787a976\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f645bc77-8532-4793-9547-99c67787a976\")) {                    Plotly.newPlot(                        \"f645bc77-8532-4793-9547-99c67787a976\",                        [{\"dimensions\":[{\"label\":\"Objective Value\",\"range\":[0.001,0.6181212464262876],\"values\":[0.001,0.45686687703647466,0.40026872829181787,0.08451711562953988,0.6181212464262876]},{\"label\":\"da\",\"range\":[50,300],\"values\":[50,250,300,200,100]},{\"label\":\"penalty\",\"range\":[0.4,1.0],\"values\":[0.4,0.4,0.4,1.0,0.4]},{\"label\":\"r\",\"range\":[5,20],\"values\":[20,10,10,5,10]}],\"labelangle\":30,\"labelside\":\"bottom\",\"line\":{\"color\":[0.001,0.45686687703647466,0.40026872829181787,0.08451711562953988,0.6181212464262876],\"colorbar\":{\"title\":{\"text\":\"Objective Value\"}},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"reversescale\":false,\"showscale\":true},\"type\":\"parcoords\"}],                        {\"title\":{\"text\":\"Parallel Coordinate Plot\"},\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f645bc77-8532-4793-9547-99c67787a976');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting parameter results for self-attention\n",
    "optuna.visualization.plot_parallel_coordinate(results, params=[\"da\", \"r\",\"penalty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a306dca",
   "metadata": {
    "cell_id": "c6df4c15-7cea-409e-bd11-a93865be5bfc",
    "deepnote_cell_height": 387,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1220,
    "execution_start": 1647005496307,
    "source_hash": "af1c4e9b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_params = results.best_params\n",
    "output_size = 1\n",
    "hidden_size = best_params['hidden_size']\n",
    "vocab_size = len(sick_data.vocab)\n",
    "embedding_size = 300\n",
    "embedding_weights = sick_data.vocab.vectors\n",
    "lstm_layers = best_params['lstm_layers']\n",
    "learning_rate = best_params['learning_rate']\n",
    "fc_hidden_size = best_params['fc_hidden_size']\n",
    "max_epochs = 20\n",
    "bidirectional = False\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "## self attention config\n",
    "self_attention_config = {\n",
    "    \"hidden_size\": best_params['da'],  ## refers to variable 'da' in the ICLR paper\n",
    "    \"output_size\": best_params['r'],  ## refers to variable 'r' in the ICLR paper\n",
    "    \"penalty\": best_params['penalty'],  ## refers to penalty coefficient term in the ICLR paper\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f920415",
   "metadata": {
    "cell_id": "00013-9f8e43ae-7e5a-42d3-9aca-e2bc4cbf0a12",
    "deepnote_cell_height": 369,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 80,
    "execution_start": 1647005501550,
    "source_hash": "fb9ba82a"
   },
   "outputs": [],
   "source": [
    "## init siamese lstm\n",
    "siamese_lstm_attention = SiameseBiLSTMAttention(\n",
    "    batch_size=batch_size,\n",
    "    output_size=output_size,\n",
    "    hidden_size=hidden_size,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    embedding_weights=embedding_weights,\n",
    "    lstm_layers=lstm_layers,\n",
    "    self_attention_config=self_attention_config,\n",
    "    fc_hidden_size=fc_hidden_size,\n",
    "    device=device,\n",
    "    bidirectional=bidirectional,\n",
    ")\n",
    "## move model to device\n",
    "siamese_lstm_attention.to(device)\n",
    "optimizer = torch.optim.Adam(params=siamese_lstm_attention.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2499753",
   "metadata": {
    "cell_id": "00014-e92d535d-c8cd-49eb-9574-7069245bf7cd",
    "deepnote_cell_height": 206.59375,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 3. Training (2 points)  \n",
    "Perform the final training of the model by implementing functions in `train.py` after setting values of your best-chosen hyperparameters. Note you can use the same training function when performing hyperparameter tuning.\n",
    "- **What is a good choice of performance metric here for evaluating your model?** [Max 2-3 lines]\n",
    "- **What other performance evaluation metric can we use here for this task? Motivate your answer.**[Max 2-3 lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379c0f7",
   "metadata": {
    "cell_id": "00015-d1e47af5-7b95-47e1-8f1a-33b06fa8d056",
    "deepnote_cell_height": 899,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 77384,
    "execution_start": 1647005508680,
    "source_hash": "3b75f459"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting training...\n",
      "  0%|          | 0/20 [00:00<?, ?it/s]INFO:root:Epoch 0:\n",
      "INFO:root:Accuracy: 0.015615549750802957 Training Loss: 9.211551666259766\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 9.211551666259766 - acc: 0.015615549750802957 -- Validation loss: 0.5284193158149719 - acc: 0.01879272700172839\n",
      "  5%|▌         | 1/20 [00:03<01:12,  3.81s/it]INFO:root:Epoch 1:\n",
      "INFO:root:Accuracy: 0.05644307565969653 Training Loss: 4.692107677459717\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 4.692107677459717 - acc: 0.05644307565969653 -- Validation loss: 0.5687175393104553 - acc: 0.012255406359314436\n",
      " 10%|█         | 2/20 [00:07<01:08,  3.80s/it]INFO:root:Epoch 2:\n",
      "INFO:root:Accuracy: 0.0734773561410553 Training Loss: 4.637417316436768\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 4.637417316436768 - acc: 0.0734773561410553 -- Validation loss: 0.5248135924339294 - acc: 0.029531897582795247\n",
      " 15%|█▌        | 3/20 [00:11<01:05,  3.82s/it]INFO:root:Epoch 3:\n",
      "INFO:root:Accuracy: 0.16331699161024 Training Loss: 4.529755115509033\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 4.529755115509033 - acc: 0.16331699161024 -- Validation loss: 0.5249769687652588 - acc: 0.14785545871149303\n",
      " 20%|██        | 4/20 [00:15<01:01,  3.82s/it]INFO:root:Epoch 4:\n",
      "INFO:root:Accuracy: 0.2954132177023552 Training Loss: 4.270531177520752\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 4.270531177520752 - acc: 0.2954132177023552 -- Validation loss: 0.5151833295822144 - acc: 0.25686232937989056\n",
      " 25%|██▌       | 5/20 [00:19<00:57,  3.83s/it]INFO:root:Epoch 5:\n",
      "INFO:root:Accuracy: 0.4578309619830195 Training Loss: 3.732887029647827\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 3.732887029647827 - acc: 0.4578309619830195 -- Validation loss: 0.5019655823707581 - acc: 0.3837614792997439\n",
      " 30%|███       | 6/20 [00:23<00:54,  3.86s/it]INFO:root:Epoch 6:\n",
      "INFO:root:Accuracy: 0.5938899425551005 Training Loss: 3.055389404296875\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 3.055389404296875 - acc: 0.5938899425551005 -- Validation loss: 0.41369470953941345 - acc: 0.45346242665894754\n",
      " 35%|███▌      | 7/20 [00:27<00:50,  3.89s/it]INFO:root:Epoch 7:\n",
      "INFO:root:Accuracy: 0.6865494200864334 Training Loss: 2.5279018878936768\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 2.5279018878936768 - acc: 0.6865494200864334 -- Validation loss: 0.39975568652153015 - acc: 0.4624321340490187\n",
      " 40%|████      | 8/20 [00:30<00:46,  3.88s/it]INFO:root:Epoch 8:\n",
      "INFO:root:Accuracy: 0.7240033359943312 Training Loss: 2.2927987575531006\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 2.2927987575531006 - acc: 0.7240033359943312 -- Validation loss: 0.3915642201900482 - acc: 0.48867255402259563\n",
      " 45%|████▌     | 9/20 [00:34<00:42,  3.87s/it]INFO:root:Epoch 9:\n",
      "INFO:root:Accuracy: 0.768632341539943 Training Loss: 1.9370964765548706\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 1.9370964765548706 - acc: 0.768632341539943 -- Validation loss: 0.3807666301727295 - acc: 0.4965599753446833\n",
      " 50%|█████     | 10/20 [00:38<00:38,  3.89s/it]INFO:root:Epoch 10:\n",
      "INFO:root:Accuracy: 0.7969781647501147 Training Loss: 1.749218225479126\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 1.749218225479126 - acc: 0.7969781647501147 -- Validation loss: 0.3909226655960083 - acc: 0.4958549245757519\n",
      " 55%|█████▌    | 11/20 [00:42<00:35,  3.91s/it]INFO:root:Epoch 11:\n",
      "INFO:root:Accuracy: 0.8096190955632232 Training Loss: 1.6821821928024292\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 1.6821821928024292 - acc: 0.8096190955632232 -- Validation loss: 0.4158199429512024 - acc: 0.4999800735877447\n",
      " 60%|██████    | 12/20 [00:46<00:31,  3.91s/it]INFO:root:Epoch 12:\n",
      "INFO:root:Accuracy: 0.7731996758918833 Training Loss: 2.2190964221954346\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 2.2190964221954346 - acc: 0.7731996758918833 -- Validation loss: 0.40267881751060486 - acc: 0.4974999544826418\n",
      " 65%|██████▌   | 13/20 [00:50<00:27,  3.88s/it]INFO:root:Epoch 13:\n",
      "INFO:root:Accuracy: 0.7482092983481549 Training Loss: 2.758648157119751\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 2.758648157119751 - acc: 0.7482092983481549 -- Validation loss: 0.46273553371429443 - acc: 0.5089323314671688\n",
      " 70%|███████   | 14/20 [00:54<00:23,  3.87s/it]INFO:root:Epoch 14:\n",
      "INFO:root:Accuracy: 0.8052353913622609 Training Loss: 2.0668447017669678\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 2.0668447017669678 - acc: 0.8052353913622609 -- Validation loss: 0.4828442931175232 - acc: 0.5064125535606641\n",
      " 75%|███████▌  | 15/20 [00:58<00:19,  3.87s/it]INFO:root:Epoch 15:\n",
      "INFO:root:Accuracy: 0.8015806540494844 Training Loss: 2.0033202171325684\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 2.0033202171325684 - acc: 0.8015806540494844 -- Validation loss: 0.4409894049167633 - acc: 0.49439521542015535\n",
      " 80%|████████  | 16/20 [01:01<00:15,  3.85s/it]INFO:root:Epoch 16:\n",
      "INFO:root:Accuracy: 0.8316173705400851 Training Loss: 1.7152299880981445\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 1.7152299880981445 - acc: 0.8316173705400851 -- Validation loss: 0.3983123004436493 - acc: 0.5062158090605323\n",
      " 85%|████████▌ | 17/20 [01:05<00:11,  3.84s/it]INFO:root:Epoch 17:\n",
      "INFO:root:Accuracy: 0.8396590251458952 Training Loss: 1.538000464439392\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 1.538000464439392 - acc: 0.8396590251458952 -- Validation loss: 0.4404221177101135 - acc: 0.47916938039866697\n",
      " 90%|█████████ | 18/20 [01:09<00:07,  3.82s/it]INFO:root:Epoch 18:\n",
      "INFO:root:Accuracy: 0.846153458243478 Training Loss: 1.4682663679122925\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:Train loss: 1.4682663679122925 - acc: 0.846153458243478 -- Validation loss: 0.4015030562877655 - acc: 0.5052589723336853\n",
      " 95%|█████████▌| 19/20 [01:13<00:03,  3.85s/it]INFO:root:Epoch 19:\n",
      "INFO:root:Accuracy: 0.8532453823601089 Training Loss: 1.3998256921768188\n",
      "INFO:root:Evaluating accuracy on dev set\n",
      "INFO:root:new model saved\n",
      "INFO:root:Train loss: 1.3998256921768188 - acc: 0.8532453823601089 -- Validation loss: 0.3980199098587036 - acc: 0.5169285075023861\n",
      "100%|██████████| 20/20 [01:17<00:00,  3.86s/it]\n",
      "INFO:root:Training complete\n"
     ]
    }
   ],
   "source": [
    "tot_val_acc = train_model(\n",
    "    model=siamese_lstm_attention,\n",
    "    optimizer=optimizer,\n",
    "    dataloader=sick_dataloaders,\n",
    "    data=sick_data,\n",
    "    max_epochs=max_epochs,\n",
    "    config_dict={\n",
    "        \"device\": device,\n",
    "        \"model_name\": \"siamese_lstm_attention\",\n",
    "        \"self_attention_config\": self_attention_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c19bff",
   "metadata": {
    "cell_id": "b930ab28-ec6e-4a1d-811a-4f06565c9537",
    "deepnote_cell_height": 285,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "__Comments__\n",
    "1. We use the *Pearson correlation coefficient* as the evaluation metric for this task. In statistics, it is defined to represent the extent to which two variables are linearly dependent on each other. It's simplicity is useful to easily calculate the correlation between two vectors and so it is widely used in the sub-field of semantic similarity and textual entailment to find similarity between word or sentence embeddings of sentence pairs. Therefore it has been chosen as the primary metric in the SemEval task in the Mueller-Thygarajan AAAI paper and is also our preferred choice.\n",
    "\n",
    "2. Another performance metric that can be used is also from the SemEval tasks, which is the *Spearman's rank correlation*. It differs from Pearson correlation in the fact that it focuses on the monotonicity of the relationship of variables and used a rank based scheme to calculate correlation, whereas Pearson contains linearity assumptions. It is therefore also considered alongside Pearson's as a secondary evaluation metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7307f936",
   "metadata": {
    "cell_id": "00016-e5838a22-fb2d-4cd1-9ad4-302ca0f2a19a",
    "deepnote_cell_height": 176,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "## Part 4. Evaluation and Analysis (2 points)  \n",
    "Implement function evaluate_test_set to calculate the final accuracy of the performance evaluation metric on the test data.  \n",
    "Compare the result with the original AAAI paper. Сomment on effect of penalty loss on model capacity. Did the inclusion of the self-attention block improve the results? If yes, then how? Can you think of additional techniques to improve the results? Briefly answer these questions in the markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328e5d2a",
   "metadata": {
    "cell_id": "00017-b4b767ad-5ac3-4e45-b35f-8920fc7eaecd",
    "deepnote_cell_height": 312,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 1461,
    "execution_start": 1647005591192,
    "output_cleared": false,
    "source_hash": "798863e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Evaluating accuracy on test set\n",
      "Accuracy: 0.5606613688378107 Test Loss: 3.543844699859619\n"
     ]
    }
   ],
   "source": [
    "siamese_lstm_attention.load_state_dict(torch.load('siamese_lstm_attention.pth'))\n",
    "siamese_lstm_attention.eval()\n",
    "evaluate_test_set(\n",
    "    model=siamese_lstm_attention,\n",
    "    data_loader=sick_dataloaders,\n",
    "    config_dict={\n",
    "        \"device\": device,\n",
    "        \"model_name\": \"siamese_lstm_attention\",\n",
    "        \"self_attention_config\": self_attention_config,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e016b9",
   "metadata": {
    "cell_id": "cb989550-14a5-487e-b9a3-e710bfd8cda4",
    "deepnote_cell_height": 290.71875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "The performance of the similarity task here results in Pearson coefficient of 0.56 compared to the MaLSTM result from the AAAI paper of 0.8345. <br> The penalty loss helps us in providing meaningful predictions for the sentence embeddings. In our implementation of a model without penalty and the default parameters, the predictions were found to have similar values for each sentence. Introducing the penalty helped us overcome this redundancy. <br>\n",
    "We were unable to make any distinct observations on whether the model performs better in isolation without self-attention. However, on setting the attention parameters $r$ to 1 (becomes normal vector form) and penalty to zero, the model performance reduces to a produce results close to 0.48, giving us an inidcation that the self-attention probably works to the benefit for us <br> To improve the model performance, we might consider replacing the LSTM block with an unidirectional GRU. This is based on the results from another paper on SICK dataset for similarity task, which produces better results than the MaLSTM model. [1] \n",
    "\n",
    "[1] https://aclanthology.org/R19-1116.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb8f5ba",
   "metadata": {
    "cell_id": "dd58dc76-007e-4491-9215-be6414333dcf",
    "deepnote_cell_height": 366.796875,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# References:\n",
    "\n",
    "Text Processing: <br>\n",
    "[1] https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing <br>\n",
    "Batching of embeddings <br>\n",
    "[2] https://github.com/ngarneau/understanding-pytorch-batching-lstm/blob/master/Understanding%20Pytorch%20Batching.ipynb <br>\n",
    "Training <br>\n",
    "[3] https://pytorch.org/tutorials/beginner/basics/data_tutorial.html <br>\n",
    "Implementation <br>\n",
    "[4] https://www.kaggle.com/ashishlepcha/semantic-text-similarity <br>\n",
    "[5] https://github.com/simonjisu/nsmc_study <br>\n",
    "[6] https://github.com/yufengm/SelfAttentive <br>\n",
    "Project Organization <br>\n",
    "[7] https://github.com/shahrukhx01/nnti_hindi_bengali_sentiment_analysis <br>\n",
    "Hyperparameter Optimization (Optuna) <br>\n",
    "[8] https://optuna.org"
   ]
  }
 ],
 "metadata": {
  "deepnote": {},
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "91f033ce-032a-44a1-b53b-33f2f2d2b123",
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
